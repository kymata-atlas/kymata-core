{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e2cccc",
   "metadata": {},
   "source": [
    "## Example notebook to show how to use graph builder package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5937354",
   "metadata": {},
   "source": [
    "#### Importing data\n",
    "\n",
    "Data can be extracted from `ExpressionSet`s. We build a data structure of the following form:\n",
    "    \n",
    "- Dict{ transform_name : Hexel} where Hexel has as attributes transform, best_pairings, description, github commit and color.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f56a8c5",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-11-15T14:24:13.387536Z",
     "start_time": "2024-11-15T14:24:11.108720Z"
    }
   },
   "source": [
    "from kymata.datasets.sample import KymataMirror2023Q3Dataset\n",
    "from kymata.entities.expression import HexelExpressionSet\n",
    "from kymata.ippm.denoising_strategies import DBSCANStrategy\n",
    "from kymata.ippm.ippm import IPPM\n",
    "from kymata.ippm.plot import plot_ippm\n",
    "from kymata.plot.plot import expression_plot"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "expression_set: HexelExpressionSet = KymataMirror2023Q3Dataset().to_expressionset()",
   "id": "43262477ab06d42b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Plotting data\n",
    "\n",
    "stem_plot is a useful transform to plot all of the data in hexels. Takes the hexels data structure illustrated above as input along with title."
   ],
   "id": "6062c28d354e5e97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "expression_plot(expression_set, title='Kymata 2023 Q3 Dataset')",
   "id": "ff7e9315688d8321"
  },
  {
   "cell_type": "markdown",
   "id": "b1f013d8",
   "metadata": {},
   "source": [
    "#### Denoising\n",
    "\n",
    "The first iteration of the denoiser is a max pooling strategy. It partitions the x-axis into bins and looks for clusters of spikes in each bin for each transform. If a cluster is found, it takes the maximum. The returned hexels have the best_pairings reduced significantly."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "'''\n",
    "For more details on each algorithm, check the denoiser.py file and ctrl-f search for the names. If further details are required, you can check the relevant sklearn page too.\n",
    "Strategies\n",
    "----------\n",
    "- Max Pooler : hyperparameters = [num_clusters, bin_sz]\n",
    "               num_clusters is the threshold for a bin to be considered a cluster. default=15\n",
    "               bin_sz is the size of the bin in ms. default = 25\n",
    "- Gaussian Mixture : hyperparameters = [max_gaussians, covariance_type, max_iter, n_init, init_params, random_state]\n",
    "               max_gaussians indicates the maximum number of gaussians in the mixture. default = 5.\n",
    "               covariance_type = [full, tied, diag, spherical]. default = full\n",
    "                               specifies the covariance matrix of the Gaussians\n",
    "               max_iter is the # of iterations til stop. default = 1000.\n",
    "               n_init = # of initialisations. default = 8\n",
    "               init_params = [kmeans, k-means++, random, random_from_data]. default = kmeans\n",
    "                            specifies how to initialise the parameters\n",
    "               random_state is a seed. Set it for reproducibility. default = None\n",
    "- DBSCAN : hyperparameters = [eps, min_samples, metric, metric_params, algorithm, leaf_size, n_jobs]\n",
    "               eps is the maximum distance between two samples to be considered in the neighbourhood.\n",
    "                   default = 10.\n",
    "               min_samples the number of samples in a neighbourhood for a point to be a core point.\n",
    "                   default = 2\n",
    "               metric used to compute distance. default = euclidean. check sklearn.metrics.pairwise_distance\n",
    "               metric_params additional params for metric. default = None.\n",
    "               algorithm = [auto, ball_tree, kd_tree, brute]. default = auto\n",
    "                         the algorithm used by nearestneighbours to compute distance.\n",
    "               leaf_size leaf size for ball_tree or kd_tree. default=30\n",
    "               n_jobs is the number of processors to use. default = -1.\n",
    "- Mean Shift : hyperparameters = [bandwidth, seeds, min_bin_freq, cluster_all, n_jobs]\n",
    "               bandwidth the bandwidth of the kernel. default = 30\n",
    "               seeds seeds used to initialise kernels. default = None\n",
    "               min_bin_freq accept only those bins with at least min_bin_freq points. default = 1\n",
    "               cluster_all false means to ignore anomalies. default = False\n",
    "               n_jobs is the number of processors to use. default = -1.\n",
    "the inputs for the strategy parameters are [max pooler, gaussian mixture, dbscan, mean shift].\n",
    "'''\n",
    "# algos : denoiser.[MaxPooler, DBSCAN, GMM, MeanShift]\n",
    "\n",
    "hyperparams = {\n",
    "    \"should_normalise\": True,\n",
    "    \"should_cluster_only_latency\": True,\n",
    "    \"should_max_pool\": False,\n",
    "    \"should_shuffle\": True,\n",
    "    \"eps\": 0.005,\n",
    "    \"min_samples\": 1,\n",
    "    \"metric\": \"cosine\",\n",
    "    \"algorithm\": \"auto\",\n",
    "    \"leaf_size\": 30,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "\n",
    "denoised_es: HexelExpressionSet = DBSCANStrategy(**hyperparams).denoise(expression_set)\n",
    "\n",
    "expression_plot(denoised_es, title='Denoised')"
   ],
   "id": "5ae65e1fc0d0aa50"
  },
  {
   "cell_type": "markdown",
   "id": "1e8f3e83",
   "metadata": {},
   "source": [
    "#### Generating the Directed Graph\n",
    "\n",
    "To generate a graph, we need relations between transforms, in the form of a transform hierarchy. It is \n",
    "a dictionary containing transform names with their children. Furthermore, this dictionary needs to\n",
    "contain the input transform too. \n",
    "\n",
    "An additional input is the list of input transforms. This is so we can differentiate between the spikes and inputs. Finally, it also takes the hemisphere and title as input.\n",
    "\n",
    "The result graph has as the y-axis the latency of spike, x-axis as class partitions, and node sizes as the magnitude of the spike. "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transform_hier = {\n",
    "    # assumption: we have a list of transforms and their children transform\n",
    "    'TVL loudness (short-term)' : ['TVL loudness (instantaneous)'],\n",
    "    'TVL loudness (instantaneous)' : [\n",
    "        'TVL loudness chan 1 (instantaneous)',\n",
    "        'TVL loudness chan 2 (instantaneous)',\n",
    "        'TVL loudness chan 3 (instantaneous)',\n",
    "        'TVL loudness chan 4 (instantaneous)',\n",
    "        'TVL loudness chan 5 (instantaneous)',\n",
    "        'TVL loudness chan 6 (instantaneous)',\n",
    "        'TVL loudness chan 7 (instantaneous)',\n",
    "        'TVL loudness chan 8 (instantaneous)',\n",
    "        'TVL loudness chan 9 (instantaneous)'],\n",
    "    'TVL loudness chan 1 (instantaneous)' : ['input_cochlear_1'],\n",
    "    'TVL loudness chan 2 (instantaneous)' : ['input_cochlear_2'],\n",
    "    'TVL loudness chan 3 (instantaneous)' : ['input_cochlear_3'],\n",
    "    'TVL loudness chan 4 (instantaneous)' : ['input_cochlear_4'],\n",
    "    'TVL loudness chan 5 (instantaneous)' : ['input_cochlear_5'],\n",
    "    'TVL loudness chan 6 (instantaneous)' : ['input_cochlear_6'],\n",
    "    'TVL loudness chan 7 (instantaneous)' : ['input_cochlear_7'],\n",
    "    'TVL loudness chan 8 (instantaneous)' : ['input_cochlear_8'],\n",
    "    'TVL loudness chan 9 (instantaneous)' : ['input_cochlear_9'],\n",
    "    'input_cochlear_1' : [],\n",
    "    'input_cochlear_2' : [],\n",
    "    'input_cochlear_3' : [],\n",
    "    'input_cochlear_4' : [],\n",
    "    'input_cochlear_5' : [],\n",
    "    'input_cochlear_6' : [],\n",
    "    'input_cochlear_7' : [],\n",
    "    'input_cochlear_8' : [],\n",
    "    'input_cochlear_9' : [],\n",
    "}\n",
    "transform_colour_overrides = {\n",
    "    # Transforms and their colours to match the figures\n",
    "    'TVL loudness (short-term)' : '#d388b5',\n",
    "    'TVL loudness (instantaneous)' : '#b11e34',\n",
    "} | {\n",
    "    f'TVL loudness chan {i} (instantaneous)' : '#a201e9' for i in list('123456789')\n",
    "} | {\n",
    "    f'input_cochlear_{i}' : '#7e7e7e' for i in list('123456789')\n",
    "}\n",
    "ippm = IPPM(expression_set, hierarchy=transform_hier, denoiser=\"dbscan\", **hyperparams)\n",
    "plot_ippm(ippm, title='Loudness', figheight=7, figwidth=10, colors=transform_colour_overrides)"
   ],
   "id": "c4832c12f31ab30d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transform_hier = {\n",
    "    'Heeger horizontal acceleration' : ['Heeger horizontal velocity'],\n",
    "    'Heeger horizontal velocity' : [\n",
    "        'Heeger horizontal ME GP1', \n",
    "        'Heeger horizontal ME GP2', \n",
    "        'Heeger horizontal ME GP3',\n",
    "        'Heeger horizontal ME GP4',\n",
    "    ],\n",
    "    'Heeger horizontal ME GP1' : [f'input_photoreceptors_{i}' for i in list('12345')],\n",
    "    'Heeger horizontal ME GP2' : [f'input_photoreceptors_{i}' for i in list('12345')],\n",
    "    'Heeger horizontal ME GP3' : [f'input_photoreceptors_{i}' for i in list('12345')],\n",
    "    'Heeger horizontal ME GP4' : [f'input_photoreceptors_{i}' for i in list('12345')],\n",
    "    'input_photoreceptors_1': [],\n",
    "    'input_photoreceptors_2': [],\n",
    "    'input_photoreceptors_3': [],\n",
    "    'input_photoreceptors_4': [],\n",
    "    'input_photoreceptors_5': [],\n",
    "}\n",
    "transform_colour_overrides = {\n",
    "    # Transforms and their colours to match the figures\n",
    "    'Heeger horizontal acceleration' : '#68d366',\n",
    "    'Heeger horizontal velocity' : '#3165e0',\n",
    "    'Heeger horizontal ME GP1' : '#fdf351',\n",
    "    'Heeger horizontal ME GP2' : '#f8d748',\n",
    "    'Heeger horizontal ME GP3' : '#eda13a',\n",
    "    'Heeger horizontal ME GP4' : '#ed732e',\n",
    "} | {\n",
    "    f'input_photoreceptors_{i}' : '#7e7e7e' for i in list('12345')\n",
    "}\n",
    "ippm = IPPM(expression_set, hierarchy=transform_hier, denoiser=\"dbscan\", **hyperparams)\n",
    "plot_ippm(ippm, title='Motion', figheight=7, figwidth=10, colors=transform_colour_overrides)"
   ],
   "id": "ed83f37e54f4ac7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
