Loading apptainer version:
1.0.3
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
WhisperModel is using WhisperSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Execution time: 1019.1183545589447 seconds
